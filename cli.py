"""å‘½ä»¤è¡Œæ¥å£æ¨¡å—"""

import argparse
import json
import os
import sys
from pathlib import Path
from .analyzer import LLMMemoryAnalyzer
from .report import ReportGenerator


def load_dialogue(filepath: str) -> dict:
    """åŠ è½½å¯¹è¯JSONæ–‡ä»¶"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data
    except FileNotFoundError:
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {filepath}", file=sys.stderr)
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"é”™è¯¯: JSONè§£æå¤±è´¥: {e}", file=sys.stderr)
        sys.exit(1)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="WhatDidYouRemember - LLMè®°å¿†åˆ†æå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s examples/dialogue.json
  %(prog)s examples/dialogue.json --output report.md
  %(prog)s examples/dialogue.json --llm-api openai --api-key YOUR_KEY
        """
    )
    
    parser.add_argument(
        "dialogue_file",
        help="å¯¹è¯JSONæ–‡ä»¶è·¯å¾„"
    )
    
    parser.add_argument(
        "-o", "--output",
        default="memory_report.md",
        help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„ (é»˜è®¤: memory_report.md)"
    )
    
    parser.add_argument(
        "--llm-api",
        choices=["openai", "anthropic", "local"],
        help="ä½¿ç”¨çš„LLM API (é»˜è®¤: ä½¿ç”¨æ¨¡æ‹Ÿåˆ†æ)"
    )
    
    parser.add_argument(
        "--api-key",
        help="LLM APIå¯†é’¥"
    )
    
    parser.add_argument(
        "--model",
        default="gpt-4",
        help="ä½¿ç”¨çš„æ¨¡å‹åç§° (é»˜è®¤: gpt-4)"
    )
    
    args = parser.parse_args()
    
    # åŠ è½½å¯¹è¯æ•°æ®
    print(f"ğŸ“– åŠ è½½å¯¹è¯æ–‡ä»¶: {args.dialogue_file}")
    dialogue_data = load_dialogue(args.dialogue_file)
    
    # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
    llm_client = None
    if args.llm_api:
        llm_client = create_llm_client(args.llm_api, args.api_key, args.model)
        if not llm_client:
            print("âš ï¸  è­¦å‘Š: LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿåˆ†æ", file=sys.stderr)
    
    # åˆ›å»ºåˆ†æå™¨
    print("ğŸ” å¼€å§‹åˆ†æå¯¹è¯...")
    analyzer = LLMMemoryAnalyzer(llm_client=llm_client)
    
    # æ‰§è¡Œåˆ†æ
    memory_state = analyzer.analyze_dialogue(dialogue_data)
    
    # ç”ŸæˆæŠ¥å‘Š
    print("ğŸ“ ç”ŸæˆæŠ¥å‘Š...")
    report_generator = ReportGenerator(memory_state)
    report_generator.save_report(args.output)
    
    print(f"âœ… åˆ†æå®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")
    
    # æ‰“å°ç®€è¦ç»Ÿè®¡
    total_turns = len(memory_state.turns)
    total_memories = len(memory_state.memories)
    total_hallucinations = sum(len(t.hallucinations) for t in memory_state.turns)
    
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  - æ€»è½®æ¬¡æ•°: {total_turns}")
    print(f"  - æ€»è®°å¿†é¡¹: {total_memories}")
    print(f"  - å¹»è§‰æ€»æ•°: {total_hallucinations}")


def create_llm_client(api_type: str, api_key: str = None, model: str = "gpt-4"):
    """åˆ›å»ºLLMå®¢æˆ·ç«¯"""
    if api_type == "openai":
        try:
            import openai
            if not api_key:
                api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                print("é”™è¯¯: éœ€è¦æä¾›OpenAI APIå¯†é’¥", file=sys.stderr)
                return None
            
            class OpenAIClient:
                def __init__(self, api_key, model):
                    openai.api_key = api_key
                    self.model = model
                
                def call(self, prompt):
                    response = openai.ChatCompletion.create(
                        model=self.model,
                        messages=[{"role": "user", "content": prompt}],
                        temperature=0.3
                    )
                    return response.choices[0].message.content
            
            return OpenAIClient(api_key, model)
        except ImportError:
            print("é”™è¯¯: éœ€è¦å®‰è£…openaiåº“: pip install openai", file=sys.stderr)
            return None
    
    elif api_type == "anthropic":
        try:
            import anthropic
            if not api_key:
                api_key = os.getenv("ANTHROPIC_API_KEY")
            if not api_key:
                print("é”™è¯¯: éœ€è¦æä¾›Anthropic APIå¯†é’¥", file=sys.stderr)
                return None
            
            class AnthropicClient:
                def __init__(self, api_key, model):
                    self.client = anthropic.Anthropic(api_key=api_key)
                    self.model = model
                
                def call(self, prompt):
                    message = self.client.messages.create(
                        model=self.model,
                        max_tokens=4096,
                        messages=[{"role": "user", "content": prompt}]
                    )
                    return message.content[0].text
            
            return AnthropicClient(api_key, model)
        except ImportError:
            print("é”™è¯¯: éœ€è¦å®‰è£…anthropicåº“: pip install anthropic", file=sys.stderr)
            return None
    
    elif api_type == "local":
        # æœ¬åœ°æ¨¡å‹å®¢æˆ·ç«¯ç¤ºä¾‹ï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µå®ç°ï¼‰
        print("è­¦å‘Š: æœ¬åœ°æ¨¡å‹å®¢æˆ·ç«¯éœ€è¦è‡ªå®šä¹‰å®ç°", file=sys.stderr)
        return None
    
    return None


if __name__ == "__main__":
    main()
